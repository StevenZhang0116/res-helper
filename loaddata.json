{"path": ["testpaper/jdg2.pdf", "testpaper/jdg1.pdf", "testpaper/1-1-1.pdf"], "abstract": ["decoupled neural interfaces using synthetic gradients\n\n\u02c6\u0000a\u0000b\n\n\u0000a\u0000b\n\nha\u2192b\n\nb\n\nsb\n\nma\u2192b\n\na\n\n\u02c6\u0000a\u0000b\n\n\u0000a\u0000b\n\n\u02c6\u0000a\u0000b\n\nb\nb\n\nsb\n\nma\u2192b\n\n\u02c6\u0000a\u0000b\n\nha\u2192b\n\na\n\n\u2026\u2026\n\nfi+2\n\n\u0000i+1\n\nfi+1\n\n\u0000i\n\nfi\n\nf n\n\ni+1\n\nf i\n\n1\n\n\u2026\u2026\n\n(b)\n\nmax jaderberg 1 wojciech marian czarnecki 1 simon osindero 1 oriol vinyals 1 alex graves 1 david silver 1\n\nkoray kavukcuoglu 1\n\nabstract\n\ntraining directed neural networks typically re-\nquires forward-propagating data through a com-\nputation graph, followed by backpropagating er-\nror signal, to produce weight updates. all lay-\ners, or more generally, modules, of the network\nare therefore locked, in the sense that they must\nwait for the remainder of the network to execute\nforwards and propagate error backwards before\nthey can be updated. in this work we break this\nconstraint by decoupling modules by introduc-\ning a model of the future computation of the net-\nwork graph. these models predict what the re-\nsult of the modelled subgraph will produce using\nonly local information. in particular we ", "decoupled neural interfaces using synthetic gradients\n\nmax jaderberg 1 wojciech marian czarnecki 1 simon osindero 1 oriol vinyals 1 alex graves 1 david silver 1\n\nkoray kavukcuoglu 1\n\n7\n1\n0\n2\n\n \nl\nu\nj\n \n\n3\n\n \n \n]\n\ng\nl\n.\ns\nc\n[\n \n \n\n2\nv\n3\n4\n3\n5\n0\n\n.\n\n8\n0\n6\n1\n:\nv\ni\nx\nr\na\n\nabstract\n\ntraining directed neural networks typically re-\nquires forward-propagating data through a com-\nputation graph, followed by backpropagating er-\nror signal, to produce weight updates. all lay-\ners, or more generally, modules, of the network\nare therefore locked, in the sense that they must\nwait for the remainder of the network to execute\nforwards and propagate error backwards before\nthey can be updated. in this work we break this\nconstraint by decoupling modules by introduc-\ning a model of the future computation of the net-\nwork graph. these models predict what the re-\nsult of the modelled subgraph will produce using\nonly local information. in particular we focus on\nmodelling error gradients: by using the modelled", "distributed  hierarchical  processing\nin the  primate  cerebral  cortex\n\ndaniel j.  felleman1 and  david c. van  essen2\n\n1 department  of neurobiology and anatomy,\nuniversity of texas medical  school, houston,  texas\n77030, and  2 division of biology,  california\ninstitute  of technology,  pasadena,  california  91125\n\nin  recent  years,  many  new  cortical  areas  have  been\nidentified in the macaque monkey. the number of iden-\ntified  connections  between  areas  has  increased  even\nmore dramatically. we report here on (1) a summary of\nthe layout of cortical areas associated with vision and\nwith other modalities, (2)  a computerized database for\nstoring and representing large  amounts of  information\non connectivity patterns, and  (3) the application of these\ndata to the analysis of hierarchical organization  of the\ncerebral cortex. our analysis concentrates on the visual\nsystem,  which  includes  25  neocortical  areas  that are\npredominantly or exclusively visual in function, plu"]}